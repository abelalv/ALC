[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Algebra lineal Computacional",
    "section": "",
    "text": "1 Prefacio\nEstas son las notas de la clase de Algebra lineal computacional, en ningún momento pretenden ser un libro de texto, ni mucho menos un sustituto de las clases. Son un apoyo para los estudiantes que deseen repasar los temas vistos en clase."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introducción",
    "section": "",
    "text": "En álgebra lineal computacional es una herramienta que esta ne auge en la actualidad, ya que permite resolver diversos problemas y va de la mano con la eficiencia computacional. En este curso haremos una pequeña mirada al álgebra lineal computacional y resolveremos diferentes aplicaciones usando el lenguaje de programación Python. la primera parte de este curso se usará el libro Strang (2022) como guía. En el segunda parte del curso usaremos Sauer (2018) como guía.\n\n\n\n\nSauer, T. 2018. Numerical Analysis. Pearson Education. https://books.google.com.co/books?id=gAVTDwAAQBAJ.\n\n\nStrang, Gilbert. 2022. Introduction to Linear Algebra. SIAM."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Sauer, T. 2018. Numerical Analysis. Pearson Education. https://books.google.com.co/books?id=gAVTDwAAQBAJ.\n\n\nStrang, Gilbert. 2022. Introduction to Linear Algebra. SIAM."
  },
  {
    "objectID": "summary.html#ejemplos",
    "href": "summary.html#ejemplos",
    "title": "3  Espacios vectoriales",
    "section": "3.1 Ejemplos",
    "text": "3.1 Ejemplos\n\n\\(\\mathcal{R}̣\\)\n\\(\\mathcal{C}\\)\n\\(\\mathcal{R}^n\\)\n\\(\\mathcal{C}^n\\)\nEl conjunto de todos los vectores ortogonales a un vector dado\nEl conjunto de todas las funciones definidas en \\(\\mathcal{R}\\)\nEl conjunto de todas las funciones continuas en un intervalo dado\nEl conjunto de todas las matrices del mismo tamaño\nEl conjunto de todas las funciones diferenciables en un intervalo dado\nEl conjunto de todas las funciones que satisfacen la ecuación diferencial \\[y''+ay'+by.\\]\n\n\n3.1.1 Subespacios de un espacio vectorial\nSea \\(V\\) un espacio vectorial y \\(S\\) un subconjunto de \\(V\\), \\(S\\) es un subespacio de \\(V\\), si en si mismo es un espacio vectorial.\n\n\n\n\n\n\nTeorema\n\n\n\nSea \\(S\\) un subconjunto no vació de un espacio vectorial \\(V\\). Si los elementos de \\(S\\) satisfacen los axiomas de clausura entonces \\(S\\) es un subespacio de \\(V\\)\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(S\\) un subconjunto no vació de un espacio vectorial \\(V\\), un elemento \\(x\\) de \\(V\\) de la forma: \\[x=\\sum_{i=1}^{k}c_ix_i,\\] en donde \\(x_1,x_2,...,x_k\\) son elementos de \\(S\\) y \\(c_i\\) son escalares, se denomina la combinación lineal de elementos de \\(S\\).\n\n\n\n\n\n\n\n\nTeorema\n\n\n\nEl conjunto \\(span(S)=\\{\\sum_{i=1}^{k}c_ix_i,|c_i\\in F\\}\\) de todos los elementos generados en combinación lineal de \\(S\\) es un subespacio vectorial de \\(V\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi \\(S\\) es un subespacio de \\(V\\) entonces \\(S=span(S)\\). Además, el generado \\(gen(S)=span(S)\\)\n\n\nSupongamos que queremos calcular el \\(span(S)\\) donde \\(S\\{x_1,x_2,...,x_n\\}\\), y \\(x_i\\in\\mathbb{R^n}\\), para esto debemos calcular todas las combinaciones lineales de los elementos de \\(S\\) de la siguinete forma\n\\[span(S)=\\{\\sum_{i=1}^{n}c_ix_i,|c_i\\in\\mathbb{R}\\}\\]\nOtra forma de calcular esta combinación es crear una matriz \\(M\\) con todos los vectores de \\(S\\) y multiplicarla por un vector columna de los coeficientes \\(c_i\\), de esta forma obtenemos un vector columna con todos los elementos de la combinación lineal, esto se puedo expresar como la multiplicación de una matriz por un vector columna.\n\\[span(S)=M\\in\\mathbb{R}c\\]\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(A\\) una matriz de \\(m\\times n\\), definimos como \\(Im(A)=span\\{y\\in\\mathbb{R^m}|Ax=y\\}\\), note si tomamos \\(x=e_i\\) tenemos donde \\(Ae_i=A_i\\) son las columnas de \\(A\\). Además definimos \\(Ker(A)=\\{x\\in\\mathbb{R^n}|Ax=0\\}\\)."
  },
  {
    "objectID": "subespacios.html",
    "href": "subespacios.html",
    "title": "6  Subespacios principales de una matriz",
    "section": "",
    "text": "Una matriz \\(A_{m\\times n}\\) crea cuatro subespacios importantes, como los podemos mostrar en la siguiente figura. (Aquí se puede encontrar màs inforacion del tema)\n\n\n\n4 espacios fundamentales\n\n\nLlamaremos \\(C(A)\\) como el espacio columna de la matriz \\(A\\) y \\(N(A)\\) como el espacio nulo de la matriz de \\(A\\). De aquì podemos observar las siguientes propiedades\n\\[C(A^T)\\perp N(A).\\] Para mostrar esta proiedad debemos mostrar que si \\(x_1\\in C(A^T)\\) y \\(x_2\\in N(A)\\), entonces\n\\[\\langle x_1,x_2\\rangle=x_2^Tx_1=0.\\]\nSabemos que existe un \\(y\\in \\mathbb{R}^m\\), note que lo podemos descomponer en \\(y=y_1+y_2\\), donde \\(y_1\\in C(A)\\) y \\(y_2\\in N(A^T)\\) luego \\[A^Ty=A^T(y_1+y_2)=A^ty_1=x_1.\\]\nAhora tenemos que\n\\[\\langle x_2,x_1\\rangle=(A^Ty)^Tx_2=y^TAx_2=0,\\] por tanto son ortogonales. Con un argumento similar podemos mostrar que \\(C(A)\\perp N(A^T)\\).\nAdemas tenemos la propiedad que \\[dim(C(A))=dim(N(A^T))=r,\\] de esta forma tenemos que \\(dim(N(A))=n-r\\) y \\(dim(N(A^T))=m-r\\).\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(A\\) una matriz de \\(m\\times n\\), definimos como el \\(rank(A)\\) como el numero máximo de filas o columnas lienalmente independientes de \\(A\\). Note que por la propiedad anterior tenemos que \\(rank(A)=dim(C(A))=dim(N(A^T))\\).\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(A\\) una matriz de \\(m\\times n\\), con \\(m>n\\) \\(rank(A)=n\\) diremos que \\(A\\) es una matriz de rango completo.\n\n\nAlgunas propiedades importantes del rank son las siguientes\n\nSi \\(A\\) es una matriz cuadrada y \\(rank(A)=n\\) entonces todos autovalores de \\(A\\) son distintos de cero.\nSi \\(A\\) es una matriz cuadrada entonces \\(rank(A)=n\\) si y solo si \\(A\\) es invertible.\n\nPara demostrar la primera vamos a suponer que es falso por tanto 0 es un autovalor luego \\(Ax=0\\), lo que implica que \\(N(A)\\neq\\emptyset\\), esto contradice el hecho que \\(rank(A)=dim(C(A^T))=dim(C(A))=n\\). Ahora, si \\(A\\) tiene todos los autovalores diferentes de cero entonces \\(A\\) es invertible, por lo tanto \\(rank(A)=n\\).\n\nSi \\(A\\) una matriz de \\(m\\times n\\), con \\(m>n\\) entonces \\(A^TA\\) es invertible.\n\nSea \\(x\\in \\mathbb{R}^n\\) entonces \\(Ax=y\\neq 0\\) puesto que \\(rank(A)=n,\\) entonces \\(y\\notin N(A^T)\\). De esta forma existe un \\(x\\neq 0\\) tal que \\(x=A^Ty\\) y que \\(x\\in C(A^T)\\) y \\(x\\neq 0\\). Para completar la demostración debemos debemos mostrar que \\(dim(Im(A^TA))=n\\).\nPara esto vamos a usar la propiedad que \\(rank(A)=n\\) y \\(rank(A^T)=n\\). Entonces tenemos que \\(rank(A^TA)=n\\) y por lo tanto \\(A^TA\\) es invertible."
  },
  {
    "objectID": "espacios_vectoriales.html#ejemplos",
    "href": "espacios_vectoriales.html#ejemplos",
    "title": "3  Espacios vectoriales",
    "section": "3.1 Ejemplos",
    "text": "3.1 Ejemplos\n\n\\(\\mathcal{R}̣\\)\n\\(\\mathcal{C}\\)\n\\(\\mathcal{R}^n\\)\n\\(\\mathcal{C}^n\\)\nEl conjunto de todos los vectores ortogonales a un vector dado\nEl conjunto de todas las funciones definidas en \\(\\mathcal{R}\\)\nEl conjunto de todas las funciones continuas en un intervalo dado\nEl conjunto de todas las matrices del mismo tamaño\nEl conjunto de todas las funciones diferenciables en un intervalo dado\nEl conjunto de todas las funciones que satisfacen la ecuación diferencial \\[y''+ay'+by.\\]\n\n\n3.1.1 Subespacios de un espacio vectorial\nSea \\(V\\) un espacio vectorial y \\(S\\) un subconjunto de \\(V\\), \\(S\\) es un subespacio de \\(V\\), si en si mismo es un espacio vectorial.\n\n\n\n\n\n\nTeorema\n\n\n\nSea \\(S\\) un subconjunto no vació de un espacio vectorial \\(V\\). Si los elementos de \\(S\\) satisfacen los axiomas de clausura entonces \\(S\\) es un subespacio de \\(V\\)\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(S\\) un subconjunto no vació de un espacio vectorial \\(V\\), un elemento \\(x\\) de \\(V\\) de la forma: \\[x=\\sum_{i=1}^{k}c_ix_i,\\] en donde \\(x_1,x_2,...,x_k\\) son elementos de \\(S\\) y \\(c_i\\) son escalares, se denomina la combinación lineal de elementos de \\(S\\).\n\n\n\n\n\n\n\n\nTeorema\n\n\n\nEl conjunto \\(span(S)=\\{\\sum_{i=1}^{k}c_ix_i,|c_i\\in F\\}\\) de todos los elementos generados en combinación lineal de \\(S\\) es un subespacio vectorial de \\(V\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi \\(S\\) es un subespacio de \\(V\\) entonces \\(S=span(S)\\). Además, el generado \\(gen(S)=span(S)\\)\n\n\nSupongamos que queremos calcular el \\(span(S)\\) donde \\(S\\{x_1,x_2,...,x_n\\}\\), y \\(x_i\\in\\mathbb{R^n}\\), para esto debemos calcular todas las combinaciones lineales de los elementos de \\(S\\) de la siguiente forma\n\\[span(S)=\\{\\sum_{i=1}^{n}c_ix_i,|c_i\\in\\mathbb{R}\\}\\]\nOtra forma de calcular esta combinación es crear una matriz \\(M\\) con todos los vectores de \\(S\\) y multiplicarla por un vector columna de los coeficientes \\(c_i\\), de esta forma obtenemos un vector columna con todos los elementos de la combinación lineal, esto se puedo expresar como la multiplicación de una matriz por un vector columna.\n\\[span(S)=M\\in\\mathbb{R}c\\]\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(A\\) una matriz de \\(m\\times n\\), definimos como el espacio columna de \\(A\\)\n\\[C(A)=span\\{y\\in\\mathbb{R^m}|Ax=y\\},\\]\ny este se denota por \\(C(A)\\).\nNote si tomamos \\(x=e_i\\) tenemos donde \\(Ae_i=A_{\\cdot i}\\) es \\(i-esima\\) columna de \\(A\\). Además definimos como el espacio nulo de \\(A\\)\n\\[N(A)=span\\{x\\in\\mathbb{R^n}|Ax=0\\}.\\]\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nSe \\(S=\\{x_1,x_2,...,x_n\\}\\) un conjunto de vectores linealmente independientes de \\(V\\), entonces se dice que \\(S\\) es una base de \\(V\\) si genera a \\(V\\).\n\n\nSi el conjunto \\(S\\) es finito, entonces se dice que \\(V\\) es de dimensión finita y se denota por \\(dim(V)=n\\). Existen espacios con dimensión infinita, pero no los estudiaremos en este curso.\n\n\n\n\n\n\nDefinición\n\n\n\nEl rank de una matriz \\(A\\) es la dimensión del espacio columna de \\(A\\) y se denota por \\(rank(A)\\).\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(A\\) una matriz de \\(m\\times n\\), con \\(m>n\\) \\(rank(A)=n\\) diremos que \\(A\\) es una matriz de rango completo.\n\n\n\n\n\n\n\n\nEjercicio\n\n\n\n\n\n\nMuestre que si una matriz \\(A\\) todas sus columnas son linealmente independientes entonces el espacio nulo de \\(A\\) es el vector \\(\\{0\\}\\).\nSi \\(A\\) es una matriz de \\(m\\times n\\) y \\(B\\) es una matriz de \\(n\\times p\\) muestre que el espacio nulo de \\(AB\\) es un subespacio del espacio nulo de \\(B\\).\nSi \\(A\\) es una matriz de \\(n\\times n\\) y la dimensión de su espacio columna es \\(n\\) entonces la inversa de \\(A\\) existe."
  },
  {
    "objectID": "espacios_vectoriales.html",
    "href": "espacios_vectoriales.html",
    "title": "3  Espacios vectoriales",
    "section": "",
    "text": "4 Solución de sistema de ecuaciones lineales"
  },
  {
    "objectID": "espacios_vectoriales.html#ejercicio",
    "href": "espacios_vectoriales.html#ejercicio",
    "title": "3  Espacios vectoriales",
    "section": "3.2 Ejercicio",
    "text": "3.2 Ejercicio\nMuestre que si una matriz \\(A\\) todas sus columnas son linealmente independientes entonces el espacio nulo de \\(A\\) es el vector \\(\\{0\\}\\). #:::"
  },
  {
    "objectID": "espacios_vectoriales.html#ejercicio-1",
    "href": "espacios_vectoriales.html#ejercicio-1",
    "title": "3  Espacios vectoriales",
    "section": "3.2 Ejercicio",
    "text": "3.2 Ejercicio\n#:::"
  },
  {
    "objectID": "producto.html",
    "href": "producto.html",
    "title": "5  producto interno",
    "section": "",
    "text": "6 Producto interno en un espacio vectorial"
  },
  {
    "objectID": "producto.html#ejemplos",
    "href": "producto.html#ejemplos",
    "title": "5  Producto interno en un espacio vectorial",
    "section": "5.1 Ejemplos",
    "text": "5.1 Ejemplos\n\nEl producto punto en \\(\\mathbb{R}^n\\) es un producto interno.\nSea \\(A\\) una matriz simétrica definida positiva en \\(\\mathbb{R}^n\\) define un producto interno.\nSea \\(C^n\\) el espacio de todas las funciones continuas en el intervalo \\([a,b]\\). Entonces \\(f,g\\in C^n\\) se define el producto interno como \\[\\int_a^b f(x)g(x)dx.\\]"
  },
  {
    "objectID": "solu_ecua.html",
    "href": "solu_ecua.html",
    "title": "4  Solución de sistema de ecuaciones lineales",
    "section": "",
    "text": "Supongamos que tenemos un sistema de ecuaciones lineales de la forma:\n\\[ \\begin{align*}\na_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n &= b_1 \\\\\na_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n &= b_2 \\\\\n\\vdots \\\\\na_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n &= b_m \\\\\n\\end{align*} \\]\nnotemos que podemos escribirlo de forma matricial como:\n\\[ \\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\    \na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n\\end{pmatrix} \\begin{pmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{pmatrix} = \\begin{pmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_m \\\\\n\\end{pmatrix}, \\]\n\\[ \\begin{pmatrix}\nA_{\\cdot 1} & A_{\\cdot 2} & \\cdots & A_{\\cdot n} \\\\\n\\end{pmatrix} \\begin{pmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{pmatrix} = \\begin{pmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_m \\\\\n\\end{pmatrix}. \\]\nLa notación \\(A_{\\cdot j}\\) indica la columna \\(j\\) de la matriz \\(A\\), o de forma más compacta como:\n\\[ \\sum _{j=1}^n A_{\\cdot j}x_j = \\begin{pmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_m \\\\\n\\end{pmatrix}, \\]\nrecuerde que \\(x_j\\) es un escalar.\nAquí nos podemos preguntar si existe una solución para este sistema de ecuaciones, y si existe, ¿es única?. Para analizar esto, observemos que el sistema tiene solución si y solo si el vector \\(\\vec{b}\\) es combinación lineal de las columnas de la matriz \\(A\\), en otras palabras pertenece al espacio columna de \\(A\\). En caso contrario el sistema no tiene solución. Ahora podemos preguntarnos si la solución es única, para ellos existen dos posibilidades\n\nLas columnas de \\(A\\) son linealmente independientes, en este caso la solución es única.\nLas columnas de \\(A\\) son linealmente dependientes y \\(n<m\\), en este caso la solución no es única, esto quiere decir que \\(r<n\\).\nLas columnas de \\(A\\) son linealmente dependientes y \\(m<n\\).\n\nLa primera afirmación es una consecuencia de la definición de combinación lineal. En el segundo caso podemos ver que si las columnas de \\(A\\), son linealmente dependientes, entonces, sin perdida de generalidad, supondremos que las primeras \\(r\\) columnas son linealmente independientes, por tanto las restantes \\(n-r\\) columnas son combinación lineal de las primeras \\(r\\) columnas. Además las primeras \\(r\\) columnas son una base del espacio columna de \\(A\\), por tanto el vector \\(\\vec{b}\\) puede escribirse como combinación lineal de las primeras \\(r\\) columnas, así:\n\\[ \\vec{b} = \\sum_{j=1}^r \\tilde{\\alpha}_j A_{\\cdot j}, \\] lo cual quiere decir que un vector solución del sistema es:\n\\[ \\vec{x}_p=\\begin{pmatrix}\n\\tilde{\\alpha}_1 \\\\\n\\tilde{\\alpha}_2 \\\\\n\\vdots \\\\\n\\tilde{\\alpha}_r \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\end{pmatrix}, \\]\ndonde los últimos \\(m-r\\) elementos son cero. Ahora bien, queremos encontrar otro vector solución para ello estudiaremos la solución del sistema homogéneo asociado:\n\\[ A\\vec{x} = \\vec{0}, \\]\nrecuerde que \\(\\vec{x}\\in\\mathbb{R}^n\\) y \\(\\vec{0}\\in\\mathbb{R}^m\\). Este sistema tiene solución trivial. Sea \\(\\vec{x_h }=\\vec{x_1}+\\vec{x_2}\\), donde\n\\[ \\vec{x}_1=\\begin{pmatrix}\n\\alpha_1 \\\\\n\\alpha_2 \\\\\n\\vdots \\\\\n\\alpha_r \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\end{pmatrix}, \\text{ y } \\vec{x}_2=\\begin{pmatrix}\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\beta_{r+1} \\\\\n\\vdots \\\\\n\\beta_m \\\\\n\\end{pmatrix},\\]\ncalculando \\(A(\\vec{x}_1-\\vec{x}_2)\\) se obtiene que:\n\\[ \\sum_{j=1}^r \\alpha_j A_{\\cdot j} - \\sum_{j=r+1}^m \\beta_j A_{\\cdot j} = \\vec{0}, \\]\nluego para cualquier combinación de \\(\\beta_j\\) encontramos una combinación de \\(\\alpha_j\\) que la suma anterior sea cero, por tanto existen infinitas soluciones del sistema homogéneo asociado. Por tanto, la solución del sistema original es:\n\\[ \\vec{x} = \\vec{x}_p + \\vec{x}_h,\\] puesto \\[A(\\vec{x}_p + \\vec{x}_h) = A\\vec{x}_p + A\\vec{x}_h = \\vec{b} + \\vec{0} = \\vec{b}.\\]\n\n\n\n\n\n\nNote\n\n\n\nDe la demostración anterior podemos podemos ver que \\[ dim(N(A))=n-r. \\]\n\n\n\n\n\n\n\n\nEjercicio\n\n\n\n\n\n\nEl tercer caso es similar al segundo, la justificación se deja como ejercicio.\nMuestre que el \\(Rank(A^T)=Rank(A)\\).\nMuestre que el \\(dim((A^T))=m-r\\)."
  }
]